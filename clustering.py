import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score
from sklearn.preprocessing import StandardScaler
from utils import load_data

# Caminho do dataset
parquet_path = "dataset/parquet/tcc_ceds_music.parquet"
df = load_data(parquet_path)

if df is None:
    st.stop()

# Verificar se a coluna 'year' existe
if 'year' not in df.columns:
    if 'release_date' in df.columns:
        df['release_date'] = df['release_date'].astype(str).str.replace(",", "").str.split(".").str[0]
        df['year'] = pd.to_numeric(df['release_date'], errors='coerce')
        df['decade'] = (df['year'] // 10 * 10).astype('Int64')
    else:
        st.error("Erro: A coluna 'year' n√£o foi encontrada no dataset. Verifique o formato do arquivo.")
        st.stop()

# Garantir que os atributos sejam num√©ricos
acoustic_features = ['danceability', 'energy', 'acousticness', 'sadness', 'instrumentalness']
df[acoustic_features] = df[acoustic_features].apply(pd.to_numeric, errors='coerce')
df_filtered = df.dropna(subset=acoustic_features)

# Normalizar os dados
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_filtered[acoustic_features])

# Clusteriza√ß√£o
st.title("üîó Clusteriza√ß√£o de M√∫sicas")
st.markdown("""
Esta aplica√ß√£o utiliza **K-Means** para agrupar m√∫sicas com base em seus atributos ac√∫sticos. 
Abaixo, voc√™ pode simular a classifica√ß√£o de uma m√∫sica em um cluster inserindo os valores dos atributos.
""")

# Visualiza√ß√£o dos dados antes e depois da normaliza√ß√£o
st.write("### Visualiza√ß√£o da Normaliza√ß√£o dos Dados")

# Gr√°fico antes da normaliza√ß√£o
st.write("#### Distribui√ß√£o dos Dados Antes da Normaliza√ß√£o")
fig, ax = plt.subplots(figsize=(10, 6))
sns.boxplot(data=df_filtered[acoustic_features], ax=ax)
plt.title("Distribui√ß√£o dos Atributos Ac√∫sticos Antes da Normaliza√ß√£o")
st.pyplot(fig)

# Gr√°fico depois da normaliza√ß√£o
st.write("#### Distribui√ß√£o dos Dados Ap√≥s a Normaliza√ß√£o")
scaled_df = pd.DataFrame(scaled_data, columns=acoustic_features)
fig, ax = plt.subplots(figsize=(10, 6))
sns.boxplot(data=scaled_df, ax=ax)
plt.title("Distribui√ß√£o dos Atributos Ac√∫sticos Ap√≥s a Normaliza√ß√£o")
st.pyplot(fig)

st.write("### üéµ Simula√ß√£o de Previs√£o de Cluster")
st.markdown("""
Insira os valores dos atributos ac√∫sticos para simular a classifica√ß√£o da m√∫sica em um cluster.
""")

# Inputs para os atributos ac√∫sticos
col1, col2 = st.columns(2)
with col1:
    danceability = st.slider("Danceability", 0.0, 1.0, 0.5)
    energy = st.slider("Energy", 0.0, 1.0, 0.5)
with col2:
    acousticness = st.slider("Acousticness", 0.0, 1.0, 0.5)
    sadness = st.slider("Sadness", 0.0, 1.0, 0.5)
instrumentalness = st.slider("Instrumentalness", 0.0, 1.0, 0.5)

user_input = pd.DataFrame({
    'danceability': [danceability],
    'energy': [energy],
    'acousticness': [acousticness],
    'sadness': [sadness],
    'instrumentalness': [instrumentalness]
})

user_input_scaled = scaler.transform(user_input)

# Treinar o modelo K-Means com o conjunto de dados completo
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(scaled_data)  


predicted_cluster = kmeans.predict(user_input_scaled)


st.success(f"### üé∂ A m√∫sica pertenceria ao **Cluster {predicted_cluster[0]}**")
st.markdown(f"""
Com base nos valores inseridos, a m√∫sica foi classificada no **Cluster {predicted_cluster[0]}**.
""")

st.write("#### Clusteriza√ß√£o de M√∫sicas com Base em Danceability e Energy")
# M√©todo do Cotovelo
st.write("### M√©todo do Cotovelo")
st.markdown("""
O m√©todo do cotovelo ajuda a escolher o n√∫mero ideal de clusters. 
O ponto onde a in√©rcia come√ßa a diminuir mais lentamente (o "cotovelo") indica o n√∫mero ideal de clusters.
""")
inertia = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_data)
    inertia.append(kmeans.inertia_)

fig, ax = plt.subplots(figsize=(10, 6))
plt.plot(range(2, 11), inertia, marker='o')
plt.title('M√©todo do Cotovelo')
plt.xlabel('N√∫mero de Clusters')
plt.ylabel('In√©rcia')
st.pyplot(fig)

st.write("### üìä Visualiza√ß√£o dos Clusters")
# Definir n√∫mero de clusters
num_clusters = st.slider("Selecione o n√∫mero de clusters:", 2, 10, 4)
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
df_filtered['cluster'] = kmeans.fit_predict(scaled_data)

# Gr√°fico de Silhueta
st.write("### An√°lise de Silhueta")
silhouette_avg = silhouette_score(scaled_data, df_filtered['cluster'])
st.write(f"M√©dia do Coeficiente de Silhueta: {silhouette_avg:.2f}")

silhouette_values = silhouette_samples(scaled_data, df_filtered['cluster'])
y_lower, y_upper = 0, 0
fig, ax = plt.subplots(figsize=(10, 6))
colors = sns.color_palette("Set1", num_clusters)

for i in range(num_clusters):
    cluster_silhouette_values = silhouette_values[df_filtered['cluster'] == i]
    cluster_silhouette_values.sort()
    y_upper += len(cluster_silhouette_values)
    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_values, facecolor=colors[i], edgecolor='black')
    ax.text(-0.05, y_lower + 0.5 * len(cluster_silhouette_values), str(i))
    y_lower = y_upper

ax.axvline(x=silhouette_avg, color="red", linestyle="--")
ax.set_xlabel("Coeficiente de Silhueta")
ax.set_ylabel("Clusters")
ax.set_yticks([])
st.pyplot(fig)

# Gr√°fico de Dispers√£o dos Clusters
st.write("### Visualiza√ß√£o dos Clusters")
fig, ax = plt.subplots(figsize=(12, 6))
sns.scatterplot(x=df_filtered['danceability'], y=df_filtered['energy'], hue=df_filtered['cluster'], palette="Set1")
plt.xlabel("Danceability")
plt.ylabel("Energy")
plt.title(f"Clusters de M√∫sicas por Danceability e Energy ({num_clusters} clusters)")
st.pyplot(fig)

# Explica√ß√£o da Import√¢ncia da An√°lise
st.markdown("""
### üìä Import√¢ncia da An√°lise de Silhueta

O gr√°fico de silhueta nos permite avaliar a qualidade da clusteriza√ß√£o. Quanto maior o coeficiente de silhueta, melhor definido est√° o cluster. A linha vermelha indica a m√©dia geral, e valores negativos sugerem que algumas m√∫sicas podem estar em clusters inadequados.

Al√©m disso, a visualiza√ß√£o dos clusters nos permite identificar padr√µes e caracter√≠sticas comuns entre m√∫sicas agrupadas.
""")
