import os
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import re

# Configura√ß√µes iniciais
st.set_page_config(page_title="Sintonize", layout="wide")

# Caminho absoluto baseado no local do script
base_dir = os.path.dirname(os.path.abspath(__file__))
parquet_path = os.path.join(base_dir, "dataset/parquet/tcc_ceds_music.parquet")

# Carregando os dados
def load_data(path):
    try:
        df = pd.read_parquet(path)
        return df
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo: {e}")
        return None

df = load_data(parquet_path)
if df is None:
    st.stop()

keywords = {
    "moon_landing": ["moon", "space", "NASA", "Apollo", "landing", "rocket", "moonwalk", "Neil Armstrong", "Buzz Aldrin"],
    "cold_war": ["cold war", "soviet", "missile", "freedom", "Khrushchev", "KGB", "sputnik", "nuclear", "Berlin", "communism"]
}

# Fun√ß√£o para contar palavras-chave em um texto
def count_keywords(text, keywords_list):
    count = 0
    for word in keywords_list:
        count += text.lower().count(word.lower())
    return count

# Pr√©-processamento
df['release_date'] = df['release_date'].astype(str).str.replace(",", "").str.split(".").str[0]
df['year'] = pd.to_numeric(df['release_date'], errors='coerce')
df['decade'] = (df['year'] // 10 * 10).astype('Int64')

attributes = [ 'violence', 'world/life', 'night/time', 'shake the audience', 'family/gospel', 'romantic', 'communication', 'obscene', 'music',
'movement/places', 'light/visual perceptions', 'family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability', 'loudness', 'acousticness',
'instrumentalness', 'valence', 'energy']
df[attributes] = df[attributes].apply(pd.to_numeric, errors='coerce')

# Menu lateral 
if "current_menu" not in st.session_state:
    st.session_state.current_menu = "Vis√£o Geral"

# Fun√ß√£o para setar o menu
def set_menu(menu):
    st.session_state.current_menu = menu

st.sidebar.title("üéµ Sintonize")
st.sidebar.subheader("Selecione o detalhamento desejado abaixo:")

# Bot√µes de navega√ß√£o
if st.sidebar.button("üìÑ Vis√£o Geral"):
    set_menu("Vis√£o Geral")
if st.sidebar.button("üìä  Distribui√ß√£o por D√©cadas"):
    set_menu("Distribui√ß√£o por D√©cadas")
if st.sidebar.button("üé∂  Evolu√ß√£o Ac√∫stica"):
    set_menu("Evolu√ß√£o Ac√∫stica")
if st.sidebar.button("üåå Palavras-chave e Contexto Hist√≥rico"):
    set_menu("Palavras-chave e Contexto Hist√≥rico")
if st.sidebar.button("üîó  Clusteriza√ß√£o"):
    set_menu("Clusteriza√ß√£o")
if st.sidebar.button("üéº  Classifica√ß√£o de G√™neros"):
    set_menu("Classifica√ß√£o de G√™neros")

# Recupera o menu atual
menu = st.session_state.current_menu

st.write(f"### {menu}")


if menu == "Vis√£o Geral":
    st.title("üìä An√°lise da Evolu√ß√£o Musical ao Longo das D√©cadas")
    st.subheader("Dataset: Music Dataset : 1950 to 2019")
    st.subheader("Usabilidade: 9.41")
    st.markdown(""" O Sintonize utiliza um dataset contendo informa√ß√µes sobre m√∫sicas de diversas d√©cadas, incluindo atributos como dan√ßabilidade, energia, val√™ncia emocional e tristeza. A an√°lise busca identificar padr√µes e tend√™ncias hist√≥ricas, considerando eventos culturais e tecnol√≥gicos, como o impacto da internet nos g√™neros musicais. """)
    
    col1, col2, col3 = st.columns(3)
    df['year'] = df['year'].astype('Int64')
    col1.metric("üéµ Total de M√∫sicas", f"{len(df):,}".replace(",", "."))
    col2.metric("üóìÔ∏è Per√≠odo Coberto", f"{int(df['year'].min())} a {int(df['year'].max())}")
    col3.metric("üéº G√™neros √önicos", f"{df['genre'].nunique()}")
    st.write("### Amostra dos Dados")
    st.markdown(""" Esta tabela apresenta as **10 primeiras m√∫sicas** do dataset para uma vis√£o inicial. Cada linha representa uma m√∫sica e inclui informa√ß√µes como: - üé§ **Artista:** Quem interpretou a m√∫sica. - üéµ **Nome da m√∫sica:** O t√≠tulo da faixa. - üóìÔ∏è **Ano de lan√ßamento:** Quando a m√∫sica foi lan√ßada. - üìä **Atributos musicais:** Dados como `danceability`, `energy`, e outros, que ajudam a descrever caracter√≠sticas sonoras. """)
    st.dataframe(df.head(10))
    st.write("#### Estat√≠sticas Descritivas do Dataset")
    st.markdown(""" Esta tabela fornece uma vis√£o geral das caracter√≠sticas num√©ricas do dataset. Aqui est√£o os detalhes: - **`count`**: N√∫mero de registros n√£o nulos. - **`mean`**: M√©dia dos valores, √∫til para entender tend√™ncias gerais. - **`std`**: Desvio padr√£o, indicando a variabilidade dos dados. - **`min` e `max`**: Os valores extremos registrados. - **`25%`, `50%`, `75%`**: Quartis, mostrando como os valores est√£o distribu√≠dos. """)
    st.dataframe(df.describe())
elif menu == "Distribui√ß√£o por D√©cadas": 
    st.markdown(""" Os gr√°ficos mostram a quantidade de registros por g√™nero em cada d√©cada, ajudando a identificar as tend√™ncias musicais. - **Heatmap**: Facilita a compara√ß√£o visual dos g√™neros mais presentes ao longo do tempo. """)
    
    decades = {
        "1950-1959": (1950, 1959),
        "1960-1969": (1960, 1969),
        "1970-1979": (1970, 1979),
        "1980-1989": (1980, 1989),
        "1990-1999": (1990, 1999),
        "2000-2009": (2000, 2009),
        "2010-2019": (2010, 2019),
    }
    
    # Mapeamento por d√©cada
    decade_data = {}
    for decade, (start_year, end_year) in decades.items():
        filtered_df = df[(df['year'] >= start_year) & (df['year'] <= end_year)]
        if not filtered_df.empty:
            count_by_genre = filtered_df['genre'].value_counts()
            decade_data[decade] = count_by_genre
        else:
            decade_data[decade] = pd.Series(dtype=int)
    
    combined_data = pd.DataFrame(decade_data).fillna(0).astype(int)
    
    st.title("Distribui√ß√£o por D√©cadas")
    
    # Filtro de intervalo de anos
    if 'min_year' not in st.session_state:
        st.session_state.min_year = int(df['year'].min())
    if 'max_year' not in st.session_state:
        st.session_state.max_year = int(df['year'].max())

    min_year, max_year = st.slider(
        "Selecione o intervalo de anos para an√°lise:",
        int(df['year'].min()), int(df['year'].max()),
        (st.session_state.min_year, st.session_state.max_year)
    )

    # Atualiza os valores no session_state
    st.session_state.min_year = min_year
    st.session_state.max_year = max_year

    # Filtro de g√™neros musicais
    if 'selected_genres' not in st.session_state:
        st.session_state.selected_genres = sorted(df['genre'].dropna().unique())  # Define todos como padr√£o

    selected_genres = st.multiselect(
        "Selecione os g√™neros musicais para an√°lise:",
        options=sorted(df['genre'].dropna().unique()),
        default=st.session_state.selected_genres  # Usa o filtro armazenado no session_state
    )

    # Atualiza os filtros no session_state
    st.session_state.selected_genres = selected_genres

    # Filtragem de dados
    filtered_df = df[
        (df['year'] >= min_year) & 
        (df['year'] <= max_year) & 
        (df['genre'].isin(selected_genres))
    ]

    filtered_df['decade'] = (filtered_df['year'] // 10 * 10).astype(int)
    
    # Distribui√ß√£o de g√™neros por d√©cada
    genre_distribution = filtered_df.groupby(['decade', 'genre']).size().unstack(fill_value=0)
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.heatmap(genre_distribution, annot=False, cmap="coolwarm", ax=ax)
    plt.xticks(rotation=0, ha='center')
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center')  # 'ha' centraliza o texto
    ax.set_yticklabels(ax.get_yticklabels(), rotation=90)
    ax.set_title(f"Distribui√ß√£o de G√™neros por D√©cada ({min_year}-{max_year})")
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
    st.pyplot(fig)


elif menu == "Evolu√ß√£o Ac√∫stica":
    st.markdown("""
    A linha do tempo mostra a varia√ß√£o de atributos como **dan√ßabilidade**, **ac√∫stica** e **energia** por d√©cada. 
    Isso ajuda a observar como as caracter√≠sticas musicais evolu√≠ram ao longo dos anos.
    """)

    df_filtered = df.dropna(subset=['year'] + attributes)

    min_year, max_year = st.slider(
        "Selecione o intervalo de anos para an√°lise:",
        int(df['year'].min()), int(df['year'].max()), 
        (int(df['year'].min()), int(df['year'].max()))
    )

    filtered_df = df[(df['year'] >= min_year) & (df['year'] <= max_year)].copy()

    filtered_df['year'] = filtered_df['year'].astype(int)

    year_range = max_year - min_year

    if year_range >= 40:
        step = 10
    elif year_range >= 25:
        step = 5
    elif year_range >= 10:
        step = 2
    else:
        step = 1

    filtered_df['period'] = (filtered_df['year'] // step * step).astype(int)

    default_attributes = ["danceability", "acousticness", "energy"]

    selected_attributes = st.multiselect(
        "Escolha os atributos para an√°lise:",
        options=attributes,
        default=default_attributes 
    )

    # Agrupando por per√≠odo e calculando a m√©dia
    period_means = filtered_df.groupby('period')[selected_attributes].mean().reset_index()

    plt.figure(figsize=(12, 6))
    for attribute in selected_attributes:
        sns.lineplot(data=period_means, x="period", y=attribute, marker="o", label=attribute.capitalize())

    plt.title(f"Evolu√ß√£o dos Atributos Ac√∫sticos ({min_year}-{max_year})")
    plt.xlabel("Ano")
    plt.ylabel("M√©dia dos Atributos")
    plt.xticks(sorted(period_means['period'].unique()))  # Garante valores inteiros no eixo X
    plt.legend(title="Atributos")

    st.pyplot(plt)



if menu == "Palavras-chave e Contexto Hist√≥rico":
    # --- MOVIMENTOS SOCIAIS E DIREITOS CIVIS (1960-1970) ---
    st.markdown("### Movimentos Sociais e Direitos Civis (1960-1970)")
    st.markdown("Gr√°fico mostrando a frequ√™ncia de palavras-chave relacionadas aos direitos civis e movimentos sociais nas letras das m√∫sicas dessa √©poca, destacando o impacto cultural e social.")

    min_year_civil, max_year_civil = st.slider(
        " ",
        1950, 2019, (1960, 1970),
        key="slider_civil_rights"
    )

    filtered_df_civil_rights = df[(df['year'] >= min_year_civil) & (df['year'] <= max_year_civil)]
    keyword_counts_civil_rights = {year: 0 for year in range(min_year_civil, max_year_civil + 1)}

    keywords_civil_rights = [
        "freedom", "equality", "racism", "protest", "civil rights", "justice", "segregation", "peace", "discrimination", 
        "march", "activism", "black power", "revolution", "oppression", "human rights", "resistance", "liberation", 
        "empowerment", "suffrage", "inequality"
    ]

    for _, row in filtered_df_civil_rights.iterrows():
        lyrics = str(row['lyrics'])
        year = int(row['year'])
        keyword_counts_civil_rights[year] += count_keywords(lyrics, keywords_civil_rights)

    keyword_df_civil_rights = pd.DataFrame(list(keyword_counts_civil_rights.items()), columns=["Year", "Count"])
    keyword_df_civil_rights["Year"] = keyword_df_civil_rights["Year"].astype(int)

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(keyword_df_civil_rights["Year"], keyword_df_civil_rights["Count"], color='lightgreen')
    ax.set_title(f"Frequ√™ncia de Palavras-chave sobre Movimentos Sociais e Direitos Civis ({min_year_civil}-{max_year_civil})", fontsize=16)
    ax.set_xlabel("Ano", fontsize=12)
    ax.set_ylabel("Contagem de Palavras-chave", fontsize=12)

    ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))

    st.pyplot(fig)


    # --- CHEGADA A LUA ---
    st.markdown("### Chegada √† Lua (1967-1972)")
    st.markdown("Gr√°fico mostrando a frequ√™ncia de palavras-chave relacionadas √† miss√£o Apollo nas letras, destacando o impacto cultural do evento.")

    min_year_moon, max_year_moon = st.slider(
        " ",
        1950, 2019, (1967, 1972),
        key="slider_moon"
    )

    filtered_df_moon = df[(df['year'] >= min_year_moon) & (df['year'] <= max_year_moon)]
    keyword_counts_moon = {year: 0 for year in range(min_year_moon, max_year_moon + 1)}

    for _, row in filtered_df_moon.iterrows():
        lyrics = str(row['lyrics'])
        year = row['year']
        keyword_counts_moon[year] += count_keywords(lyrics, keywords["moon_landing"])

    keyword_df_moon = pd.DataFrame(keyword_counts_moon.items(), columns=["Year", "Count"])
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(keyword_df_moon["Year"], keyword_df_moon["Count"], color='skyblue')
    ax.set_title(f"Frequ√™ncia de Palavras-chave sobre a Chegada √† Lua ({min_year_moon}-{max_year_moon})", fontsize=16)
    ax.set_xlabel("Ano", fontsize=12)
    ax.set_ylabel("Contagem de Palavras-chave", fontsize=12)
    st.pyplot(fig)

    # --- GUERRA FRIA ---
    st.markdown("### Guerra Fria (1950-1980)")
    st.markdown("Gr√°fico destacando palavras-chave sobre a Guerra Fria, mostrando sua influ√™ncia em diferentes d√©cadas.")

    min_year_cold, max_year_cold = st.slider(
        " ",
        1950, 2019, (1950, 1980),
        key="slider_cold_war"
    )

    filtered_df_cold_war = df[(df['year'] >= min_year_cold) & (df['year'] <= max_year_cold)]
    keyword_counts_cold_war = {year: 0 for year in range(min_year_cold, max_year_cold + 1)}

    for _, row in filtered_df_cold_war.iterrows():
        lyrics = str(row['lyrics'])
        year = row['year']
        keyword_counts_cold_war[year] += count_keywords(lyrics, keywords["cold_war"])

    keyword_df_cold_war = pd.DataFrame(keyword_counts_cold_war.items(), columns=["Year", "Count"])
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.bar(keyword_df_cold_war["Year"], keyword_df_cold_war["Count"], color='salmon')
    ax.set_title(f"Frequ√™ncia de Palavras-chave sobre a Guerra Fria ({min_year_cold}-{max_year_cold})", fontsize=16)
    ax.set_xlabel("Ano", fontsize=12)
    ax.set_ylabel("Contagem de Palavras-chave", fontsize=12)
    st.pyplot(fig)



elif menu == "Clusteriza√ß√£o":
    st.markdown("""
    ### Agrupamento Baseado em Atributos Ac√∫sticos
    Utilizando K-Means para agrupar m√∫sicas com base em seus atributos ac√∫sticos, destacando padr√µes e semelhan√ßas.
    """)

    # Clusteriza√ß√£o inicial (exemplo j√° existente no c√≥digo)
    acoustic_features = ['danceability', 'energy', 'acousticness']
    df_filtered = df.dropna(subset=acoustic_features)

    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(df_filtered[acoustic_features])

    kmeans = KMeans(n_clusters=3, random_state=42)
    df_filtered['cluster'] = kmeans.fit_predict(scaled_data)

    plt.figure(figsize=(12, 6))
    sns.scatterplot(x=df_filtered['danceability'], y=df_filtered['energy'], hue=df_filtered['cluster'], palette="Set1")
    plt.title("Clusteriza√ß√£o de M√∫sicas com Base em Danceability e Energy", fontsize=16)
    plt.xlabel("Danceability", fontsize=12)
    plt.ylabel("Energy", fontsize=12)
    st.pyplot(plt)

    # Nova an√°lise: Clusteriza√ß√£o com 'sadness' e 'energy'
    st.markdown("""
    ### Atributos "Sadness" e "Energy"
    Outro agrupamento baseado em tristeza e energia, destacando faixas melanc√≥licas ou intensas.
    """)

    acoustic_features = ['sadness', 'acousticness', 'energy']  # Alterando 'danceability' para 'sadness'
    acoustic_features = ['sadness', 'acousticness', 'energy']
    df_filtered_sadness = df.dropna(subset=acoustic_features)

    # Normalizar os dados para o modelo de clusteriza√ß√£o
    scaler = StandardScaler()
    scaled_data_sadness = scaler.fit_transform(df_filtered_sadness[acoustic_features])

    # Realizar clusteriza√ß√£o com K-Means
    kmeans = KMeans(n_clusters=3, random_state=42)
    df_filtered_sadness['cluster'] = kmeans.fit_predict(scaled_data_sadness)

    # Visualizar os clusters
    plt.figure(figsize=(12, 6))
    sns.scatterplot(x=df_filtered_sadness['sadness'], y=df_filtered_sadness['energy'], hue=df_filtered_sadness['cluster'], palette="Set1")
    plt.title("Clusteriza√ß√£o de M√∫sicas com Base em Atributos Ac√∫sticos", fontsize=16)
    plt.xlabel("Sadness", fontsize=12)
    plt.ylabel("Energy", fontsize=12)
    st.pyplot(plt)

elif menu == "Classifica√ß√£o de G√™neros":
    # Definir palavras-chave para cada g√™nero musical
    keywords = {
        "blues": ["sad", "blues", "heartbreak", "crying", "rain"],
        "country": ["cowboy", "boots", "country", "ranch", "honky", "tumbleweed"],
        "pop": ["party", "love", "dance", "night", "club", "girl", "boy"],
        "hip_hop": ["rap", "street", "flow", "beat", "b-boy", "gangsta"],
        "jazz": ["improvisation", "saxophone", "swing", "blues", "jazz"],
        "reggae": ["rasta", "dub", "jah", "roots", "bob", "rastafari"],
        "rock": ["guitar", "rock", "band", "concert", "stage", "electric"]
    }


    df = df.dropna(subset=['lyrics', 'genre'])
    df['lyrics'] = df['lyrics'].fillna('')

    # Preparar os dados para a classifica√ß√£o
    X = []
    y = []

    # Para cada m√∫sica, contar as palavras-chave de cada g√™nero
    for _, row in df.iterrows():
        lyrics = str(row['lyrics'])
        genre = row['genre']

        # Contar as palavras-chave de cada g√™nero
        genre_counts = {}
        for genre_name, genre_keywords in keywords.items():
            genre_counts[genre_name] = count_keywords(lyrics, genre_keywords)
        
        # Adicionar os dados ao conjunto X e o r√≥tulo ao conjunto y
        X.append(list(genre_counts.values()))
        y.append(genre)

    # Converter X e y em DataFrame/arrays
    X = pd.DataFrame(X, columns=keywords.keys())
    y = pd.Series(y)

    # Dividir os dados em treino e teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Treinar o modelo Random Forest
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)

    # Fazer previs√µes no conjunto de teste
    y_pred = rf.predict(X_test)

    # Exibir as m√©tricas de avalia√ß√£o
    report = classification_report(y_test, y_pred, target_names=keywords.keys(), output_dict=True)
    st.write("M√©tricas de Avalia√ß√£o:")
    st.write(f"Precision, Recall, F1-Score e Support para cada G√™nero:")
    st.write("Random Forest")

    # Mostrar as m√©tricas de avalia√ß√£o
    metrics_df = pd.DataFrame(report).transpose()
    st.dataframe(metrics_df)
    st.markdown("""
    A accuracy de 0.25 e a baixa precision, recall e F1-score tanto na macro quanto na weighted average indicam que o modelo est√° tendo 
    dificuldades para identificar corretamente os g√™neros. 
    Ajustes futuros podem melhorar o desempenho ao adicionar mais palavras-chave ou ao treinar com dados mais equilibrados.
    """)